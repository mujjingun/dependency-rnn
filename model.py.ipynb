{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import jamo\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = 'ᐁ' # Root of sentence symbol\n",
    "MS = 'ᑌ' # morpheme separator symbol\n",
    "WS = 'ᐯ' # word separator symbol\n",
    "EOS = 'ᕒ' # end of sentence symbol\n",
    "ESC_BEGIN = 'ᐸ' # beginning of escape sequence symbol\n",
    "ESC_END = 'ᐳ' # end of escape sequence symbol\n",
    "PADDING = 'ᒣ' # padding after end-of-sentence\n",
    "MASK = 'ᗰ' # masking symbol\n",
    "hangul = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'] + \\\n",
    "    [ESC_BEGIN, ESC_END, ROOT, MS, WS, EOS, PADDING, MASK] + \\\n",
    "    [chr(i) for i in range(0x1100, 0x1113)] + \\\n",
    "    [chr(i) for i in range(0x1161, 0x1176)] + \\\n",
    "    [chr(i) for i in range(0x11A8, 0x11C3)] + \\\n",
    "    [' ', '(', ')', '.', ',', '?', '\\\"\"', '\\'']\n",
    "PADDING_IDX = hangul.index(PADDING)\n",
    "MASK_IDX = hangul.index(MASK)\n",
    "def encode_string(s):\n",
    "    compat_jamos = [chr(i) for i in range(0x3131, 0x314f)]\n",
    "    s = jamo.h2j(s)\n",
    "    s = \"\".join(jamo.hcj2j(ch, \"tail\") if ch in compat_jamos else ch for ch in s)\n",
    "    def escape(ch):\n",
    "        return [10] + [hangul.index(c) for c in str(ord(ch))] + [11]\n",
    "    result = []\n",
    "    for ch in s:\n",
    "        if ch in hangul:\n",
    "            result.append(hangul.index(ch))\n",
    "        else:\n",
    "            result += escape(ch)\n",
    "    return result\n",
    "\n",
    "def decode_string(s):\n",
    "    result = []\n",
    "    i = 0\n",
    "    while i < len(s):\n",
    "        if s[i] == PADDING_IDX:\n",
    "            break\n",
    "        if s[i] == 10:\n",
    "            ch = '0'\n",
    "            i += 1\n",
    "            while i < len(s) and s[i] < 10:\n",
    "                ch += str(s[i])\n",
    "                i += 1\n",
    "            result.append(chr(int(ch)))\n",
    "        else:\n",
    "            result.append(hangul[s[i]])\n",
    "        i += 1\n",
    "    return \"\".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_in_length = 600\n",
    "max_out_length = 700\n",
    "max_dep_length = 90\n",
    "\n",
    "\"\"\"\n",
    "CoNLL-U Format\n",
    "ID: Word index, integer starting at 1 for each new sentence; may be a range for multiword tokens; may be a decimal number for empty nodes (decimal numbers can be lower than 1 but must be greater than 0).\n",
    "FORM: Word form or punctuation symbol.\n",
    "LEMMA: Lemma or stem of word form.\n",
    "UPOS: Universal part-of-speech tag.\n",
    "XPOS: Language-specific part-of-speech tag; underscore if not available.\n",
    "FEATS: List of morphological features from the universal feature inventory or from a defined language-specific extension; underscore if not available.\n",
    "HEAD: Head of the current word, which is either a value of ID or zero (0).\n",
    "DEPREL: Universal dependency relation to the HEAD (root iff HEAD = 0) or a defined language-specific subtype of one.\n",
    "DEPS: Enhanced dependency graph in the form of a list of head-deprel pairs.\n",
    "MISC: Any other annotation.\n",
    "\"\"\"\n",
    "def read_conllu(filenames):\n",
    "    texts = []\n",
    "    morphs = []\n",
    "    depends = []\n",
    "    for filename in filenames:\n",
    "        with open(filename) as fp:\n",
    "            for line in fp.readlines():\n",
    "                if line.startswith('#'):\n",
    "                    if line.startswith('# text = '):\n",
    "                        texts.append([])\n",
    "                        morphs.append([ROOT])\n",
    "                        depends.append([])\n",
    "                else:\n",
    "                    split = line.split('\\t')\n",
    "                    if len(split) != 10:\n",
    "                        continue\n",
    "                    idx, form, lemma, upos, xpos, feats, head, deprel, deps, misc = split\n",
    "                    \n",
    "                    if \"SpaceAfter=No\" not in misc:\n",
    "                        form += ' '\n",
    "                    texts[-1].append(encode_string(form))\n",
    "                    \n",
    "                    lemma = MS.join(lemma.split('+')) + WS\n",
    "                    morphs[-1].append(lemma)\n",
    "                    depends[-1].append(int(head) - 1)\n",
    "    \n",
    "    for i in range(len(morphs)):\n",
    "        morphs[i][-1] += EOS\n",
    "    morphs = [[encode_string(w) for w in m] for m in morphs]\n",
    "    \n",
    "    dep_lengths = []\n",
    "    depend_idxs = []\n",
    "    depend_aligns = []\n",
    "    for text, morph, depend in zip(texts, morphs, depends):\n",
    "        word_cum_lengths = np.cumsum([len(w) for w in text])\n",
    "        morph_cum_lengths = np.cumsum([len(w) for w in morph])\n",
    "        \n",
    "        indices = morph_cum_lengths[1:] - 1\n",
    "        pad_size = max_dep_length - len(indices)\n",
    "        indices = np.pad(indices, (0, pad_size), 'constant')\n",
    "        depend_idxs.append(indices)\n",
    "        \n",
    "        for i in range(len(depend)):\n",
    "            depend[i] = word_cum_lengths[i] - 1\n",
    "        dep_lengths.append(len(depend))\n",
    "        depend_aligns.append(np.pad(depend, (0, pad_size), 'constant'))\n",
    "    \n",
    "    text_lengths = []\n",
    "    for i in range(len(texts)):\n",
    "        texts[i] = sum(texts[i], [])\n",
    "        text_lengths.append(len(texts[i]))\n",
    "        texts[i] += [PADDING_IDX] * (max_in_length - len(texts[i]))\n",
    "        \n",
    "    out_lengths = []\n",
    "    for i in range(len(morphs)):\n",
    "        morphs[i] = sum(morphs[i], [])\n",
    "        out_lengths.append(len(morphs[i]))\n",
    "        morphs[i] += [PADDING_IDX] * (max_out_length - len(morphs[i]))\n",
    "    \n",
    "    return {'inputs': np.array(texts, dtype=np.int32), \n",
    "            'in_lengths': np.array(text_lengths, dtype=np.int32),\n",
    "            'depend_idxs': np.array(depend_idxs, dtype=np.int32),\n",
    "            'depends': np.array(depend_aligns, dtype=np.int32),\n",
    "            'dep_lengths': np.array(dep_lengths, dtype=np.int32), \n",
    "            'morphs': np.array(morphs, dtype=np.int32),\n",
    "            'out_lengths': np.array(out_lengths, dtype=np.int32)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading input files...\n",
      "Reading from .npy...\n",
      "Done.\n",
      "Training set size: 27410\n",
      "Test set size: 3276\n"
     ]
    }
   ],
   "source": [
    "reparse = False\n",
    "\n",
    "print(\"Reading input files...\")\n",
    "if not reparse and os.path.exists('train.npy'):\n",
    "    print(\"Reading from .npy...\")\n",
    "    train = np.load('train.npy').item()\n",
    "    test = np.load('test.npy').item()\n",
    "else:\n",
    "    print(\"Parsing ConLLU database...\")\n",
    "    train = read_conllu([\n",
    "        'UD_Korean-GSD/ko_gsd-ud-train.conllu',\n",
    "        'UD_Korean-kaist/ko_kaist-ud-train.conllu'])\n",
    "    test  = read_conllu([\n",
    "        'UD_Korean-GSD/ko_gsd-ud-test.conllu',\n",
    "        'UD_Korean-kaist/ko_kaist-ud-test.conllu'])\n",
    "\n",
    "    # Save to file for later\n",
    "    np.save('train.npy', train)\n",
    "    np.save('test.npy', test)\n",
    "    \n",
    "print(\"Done.\")\n",
    "print(\"Training set size:\", len(train['inputs']))\n",
    "print(\"Test set size:\", len(test['inputs']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatOutputAndAttentionWrapper(tf.contrib.rnn.RNNCell):\n",
    "    '''Concatenates RNN cell output with the attention context vector.\n",
    "\n",
    "    This is expected to wrap a cell wrapped with an AttentionWrapper constructed with\n",
    "    attention_layer_size=None and output_attention=False. Such a cell's state will include an\n",
    "    \"attention\" field that is the context vector.\n",
    "    '''\n",
    "    def __init__(self, cell):\n",
    "        super(ConcatOutputAndAttentionWrapper, self).__init__()\n",
    "        self._cell = cell\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return self._cell.state_size\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return self._cell.output_size + self._cell.state_size.attention\n",
    "\n",
    "    def call(self, inputs, state):\n",
    "        output, res_state = self._cell(inputs, state)\n",
    "        return tf.concat([output, res_state.attention], axis=-1), res_state\n",
    "\n",
    "    def zero_state(self, batch_size, dtype):\n",
    "        return self._cell.zero_state(batch_size, dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('model', reuse=tf.AUTO_REUSE):\n",
    "    char_embed_table = tf.get_variable('embedding', \n",
    "                            [len(hangul), 256], # number of symbols, embedding vector size\n",
    "                            dtype=tf.float32,\n",
    "                            initializer=tf.truncated_normal_initializer(stddev=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder:\n",
    "    # inputs: (batch, input_length)\n",
    "    def __init__(self, inputs, lengths, is_training):\n",
    "        self.inputs = inputs\n",
    "        self.lengths = lengths\n",
    "        \n",
    "        char_embedded_inputs = tf.nn.embedding_lookup(char_embed_table, inputs)\n",
    "        \n",
    "        # 3 convolution layers\n",
    "        x = char_embedded_inputs\n",
    "        with tf.variable_scope('prenet'):\n",
    "            layer_sizes = [256, 256, 256]\n",
    "            drop_rate = 0.1 if is_training else 0.0\n",
    "            for i, size in enumerate(layer_sizes):\n",
    "                conv_layer = tf.layers.Conv1D(filters=size, # number of output channels\n",
    "                                              kernel_size=5,\n",
    "                                              padding=\"same\",\n",
    "                                              activation=tf.nn.relu,\n",
    "                                              name=\"conv_{}\".format(i))\n",
    "                x = conv_layer.apply(x)\n",
    "                tf.layers.dropout(x, \n",
    "                                  rate=drop_rate, \n",
    "                                  name=\"dropout_{}\".format(i))\n",
    "        conv_result = x\n",
    "        \n",
    "        num_hidden = 128\n",
    "        lstm_fw_cell = tf.nn.rnn_cell.LSTMCell(num_hidden, forget_bias=1.0)\n",
    "        lstm_bw_cell = tf.nn.rnn_cell.LSTMCell(num_hidden, forget_bias=1.0)\n",
    "        outputs, rnn_states = tf.nn.bidirectional_dynamic_rnn(\n",
    "            cell_fw=lstm_fw_cell,\n",
    "            cell_bw=lstm_bw_cell,\n",
    "            inputs=conv_result,\n",
    "            sequence_length=lengths,\n",
    "            dtype=tf.float32)\n",
    "        output_concat = tf.concat(list(outputs), -1)\n",
    "        \n",
    "        self.output = output_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_scatter(indices, updates, shape):\n",
    "    updates = tf.reshape(updates, [-1, shape[2]])\n",
    "    indices = indices + tf.expand_dims(tf.range(0, shape[0]) * shape[1], 1)\n",
    "    indices = tf.reshape(indices, [-1, 1])\n",
    "\n",
    "    scatter = tf.scatter_nd(indices, updates, [shape[0]*shape[1], shape[2]])\n",
    "    scatter = tf.reshape(scatter, shape)\n",
    "    return scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder:\n",
    "    # encoder_outputs: (batch, input_length, 256)\n",
    "    # depend_targets: (batch, input_length)\n",
    "    def __init__(self, encoder_outputs, depend_targets, depend_idxs, morph_targets, out_lengths, is_training):\n",
    "        self.out_lengths = out_lengths\n",
    "        \n",
    "        cells = []\n",
    "        num_hidden = 256\n",
    "        keep_rate = 0.9 if is_training else 1.0\n",
    "        for layer_index in range(2):\n",
    "            lstm_cell = tf.nn.rnn_cell.LSTMCell(num_hidden, forget_bias=1.0)\n",
    "            cell = tf.contrib.rnn.DropoutWrapper(lstm_cell, input_keep_prob=keep_rate)\n",
    "            cells.append(cell)\n",
    "        prenet = tf.contrib.rnn.MultiRNNCell(cells)\n",
    "        \n",
    "        attention_size = 256\n",
    "        attention_mechanism = tf.contrib.seq2seq.BahdanauAttention(\n",
    "            attention_size, \n",
    "            encoder_outputs,\n",
    "            normalize=True)\n",
    "        \n",
    "        attention_cell = ConcatOutputAndAttentionWrapper(\n",
    "            tf.contrib.seq2seq.AttentionWrapper(\n",
    "                prenet, \n",
    "                attention_mechanism,\n",
    "                output_attention=False))\n",
    "        \n",
    "        # lookup encoder outputs from dependency indices\n",
    "        self.depend_contexts = tf.batch_gather(encoder_outputs, depend_targets)\n",
    "        \n",
    "        shape = [tf.shape(encoder_outputs)[0], tf.shape(morph_targets)[1], encoder_outputs.shape[2]]\n",
    "        depend_contexts_sparse = batch_scatter(depend_idxs, self.depend_contexts, shape)\n",
    "        \n",
    "        # lookup char embeddings\n",
    "        morph_embedded = tf.nn.embedding_lookup(char_embed_table, morph_targets)\n",
    "        \n",
    "        decoder_inputs = tf.concat([morph_embedded, depend_contexts_sparse], axis=-1) # (batch, max_out_len, 512)\n",
    "        \n",
    "        # mask 15% of the lengths of the decoder inputs randomly\n",
    "        if is_training:\n",
    "            print(\"training mask\")\n",
    "        \n",
    "            batch_size = tf.shape(decoder_inputs)[0]\n",
    "            max_out_len = tf.shape(decoder_inputs)[1]\n",
    "            \n",
    "            mask_lengths = tf.to_int32(tf.to_float(out_lengths) * 0.15)\n",
    "            offset_bounds = out_lengths - mask_lengths - 1\n",
    "            offsets = tf.to_int32(tf.random.uniform([batch_size]) * tf.to_float(offset_bounds))\n",
    "            \n",
    "            rng = tf.range(max_out_len)\n",
    "            mask = tf.math.logical_and(\n",
    "                tf.expand_dims(rng, 0) >= tf.expand_dims(offsets, -1), \n",
    "                tf.expand_dims(rng, 0) < tf.expand_dims(offsets + mask_lengths, -1))\n",
    "            mask = tf.broadcast_to(tf.expand_dims(mask, -1), tf.shape(decoder_inputs))\n",
    "            \n",
    "            mask_symbol = tf.concat([char_embed_table[MASK_IDX], tf.zeros([num_hidden])], -1)\n",
    "            mask_symbol = tf.expand_dims(tf.expand_dims(mask_symbol, 0), 0)\n",
    "            mask_symbol = tf.broadcast_to(mask_symbol, tf.shape(decoder_inputs))\n",
    "            \n",
    "            decoder_inputs = tf.where(mask, mask_symbol, decoder_inputs)\n",
    "            \n",
    "        self.decoder_inputs = decoder_inputs\n",
    "        \n",
    "        output, rnn_states = tf.nn.dynamic_rnn(\n",
    "            cell=attention_cell,\n",
    "            inputs=decoder_inputs,\n",
    "            sequence_length=out_lengths,\n",
    "            dtype=tf.float32)\n",
    "        \n",
    "        self.char_output = tf.layers.dense(output[:, :, :num_hidden], len(hangul))\n",
    "        depend_output = output[:, :, num_hidden:]\n",
    "        \n",
    "        self.depend_output = tf.batch_gather(depend_output, depend_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_distance(a, b):\n",
    "    return tf.einsum('ijk,ijk->ij', a, b) / (tf.norm(a, axis=2) * tf.norm(b, axis=2))\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, batch, is_training):\n",
    "        with tf.variable_scope('model', reuse=tf.AUTO_REUSE):\n",
    "            self.encoder = encoder = Encoder(batch['inputs'], batch['in_lengths'], is_training)\n",
    "            self.decoder = decoder = Decoder(encoder.output, batch['depends'], batch['depend_idxs'],\n",
    "                              batch['morphs'], batch['out_lengths'], is_training)\n",
    "\n",
    "            # dependency analyzer loss\n",
    "            depend_seq_loss = cosine_distance(decoder.depend_contexts, decoder.depend_output)\n",
    "            \n",
    "            depend_mask = tf.math.equal(batch['depends'], 0)\n",
    "            depend_count = tf.to_float(tf.reduce_sum(batch['dep_lengths']))\n",
    "            \n",
    "            depend_masked_loss = tf.where(depend_mask, tf.zeros_like(depend_seq_loss), depend_seq_loss)\n",
    "            self.depend_loss = tf.reduce_sum(depend_masked_loss) / depend_count\n",
    "\n",
    "            # morpheme analyzer loss\n",
    "            char_seq_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                labels=batch['morphs'],\n",
    "                logits=decoder.char_output)\n",
    "\n",
    "            mask = tf.math.equal(batch['morphs'], PADDING_IDX)\n",
    "            total_length = tf.to_float(tf.reduce_sum(batch['out_lengths']))\n",
    "\n",
    "            char_masked_loss = tf.where(mask, tf.zeros_like(char_seq_loss), char_seq_loss)\n",
    "            self.char_loss = tf.reduce_sum(char_masked_loss) / total_length\n",
    "\n",
    "            # sum of the losses\n",
    "            self.total_loss = self.depend_loss + self.char_loss\n",
    "\n",
    "            # training-specific\n",
    "            self.global_step = tf.get_variable(\"global_step\", shape=[], trainable=False,\n",
    "                                      initializer=tf.zeros_initializer, dtype=tf.int32)\n",
    "\n",
    "            step = tf.cast(self.global_step + 1, dtype=tf.float32)\n",
    "\n",
    "            learning_rate = 1e-4 * tf.train.exponential_decay(1., step, 3000, 0.95)\n",
    "\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate, 0.9, 0.999)\n",
    "            gradients, variables = zip(*optimizer.compute_gradients(self.total_loss))\n",
    "            clipped_gradients, _ = tf.clip_by_global_norm(gradients, 1.0)\n",
    "\n",
    "            self.optimize = optimizer.apply_gradients(zip(clipped_gradients, variables), global_step=self.global_step)\n",
    "            \n",
    "            self.training_summary = tf.summary.merge([\n",
    "                tf.summary.scalar(\"total_loss\", self.total_loss),\n",
    "                tf.summary.scalar(\"char_loss\", self.char_loss),\n",
    "                tf.summary.scalar(\"depend_loss\", self.depend_loss)\n",
    "            ])\n",
    "            \n",
    "            self.validation_summary = tf.summary.merge([\n",
    "                tf.summary.scalar(\"validation_total_loss\", self.total_loss),\n",
    "                tf.summary.scalar(\"validation_char_loss\", self.char_loss),\n",
    "                tf.summary.scalar(\"validation_depend_loss\", self.depend_loss)\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training marker\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "\n",
    "inputs_placeholder = tf.placeholder(name='inputs_placeholder', \n",
    "                                    shape=(None, max_in_length), \n",
    "                                    dtype=tf.int32)\n",
    "in_lengths_placeholder = tf.placeholder(name='in_lengths_placeholder',\n",
    "                                        shape=(None),\n",
    "                                        dtype=tf.int32)\n",
    "depend_idxs_placeholder = tf.placeholder(name='depend_idxs_placeholder',\n",
    "                                         shape=(None, max_dep_length),\n",
    "                                         dtype=tf.int32)\n",
    "depends_placeholder = tf.placeholder(name='depends_placeholder',\n",
    "                                     shape=(None, max_dep_length),\n",
    "                                     dtype=tf.int32)\n",
    "dep_lengths_placeholder = tf.placeholder(name='dep_lengths_placeholder',\n",
    "                                         shape=(None),\n",
    "                                         dtype=tf.int32)\n",
    "morphs_placeholder = tf.placeholder(name='morphs_placeholder',\n",
    "                                    shape=(None, max_out_length),\n",
    "                                    dtype=tf.int32)\n",
    "out_lengths_placeholder = tf.placeholder(name='out_lengths_placeholder',\n",
    "                                         shape=(None),\n",
    "                                         dtype=tf.int32)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices({\n",
    "    'inputs': inputs_placeholder,\n",
    "    'in_lengths': in_lengths_placeholder, \n",
    "    'depend_idxs': depend_idxs_placeholder,\n",
    "    'depends': depends_placeholder,\n",
    "    'dep_lengths': dep_lengths_placeholder,\n",
    "    'morphs': morphs_placeholder,\n",
    "    'out_lengths': out_lengths_placeholder\n",
    "})\n",
    "train_dataset = dataset.shuffle(buffer_size=10000)\n",
    "train_dataset = train_dataset.repeat()\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "\n",
    "test_dataset = dataset.take(batch_size)\n",
    "test_dataset = test_dataset.batch(batch_size)\n",
    "    \n",
    "iterator = train_dataset.make_initializable_iterator()\n",
    "\n",
    "model = Model(iterator.get_next(), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate session\n",
    "saver = tf.train.Saver()\n",
    "sess = tf.Session()\n",
    "\n",
    "train_writer = tf.summary.FileWriter(\"logs\", sess.graph)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "feed_dict={\n",
    "    inputs_placeholder: train['inputs'],\n",
    "    in_lengths_placeholder: train['in_lengths'],\n",
    "    depend_idxs_placeholder: train['depend_idxs'],\n",
    "    depends_placeholder: train['depends'],\n",
    "    dep_lengths_placeholder: train['dep_lengths'],\n",
    "    morphs_placeholder: train['morphs'],\n",
    "    out_lengths_placeholder: train['out_lengths']\n",
    "}\n",
    "sess.run(iterator.initializer, feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/charrnn-4200\n"
     ]
    }
   ],
   "source": [
    "# restore checkpoint\n",
    "saver.restore(sess, \"models/charrnn-4200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot capture a placeholder (name:dep_lengths_placeholder_1, type:Placeholder) by value.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-c4a684965879>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_one_shot_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmake_one_shot_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    203\u001b[0m             \"(Original error: %s)\" % err)\n\u001b[1;32m    204\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     return iterator_ops.Iterator(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    690\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot capture a placeholder (name:dep_lengths_placeholder_1, type:Placeholder) by value."
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('test', reuse=tf.AUTO_REUSE):\n",
    "    test_dataset = dataset.take(batch_size)\n",
    "    test_dataset = test_dataset.batch(batch_size)\n",
    "    train_iterator = test_dataset.make_one_shot_iterator()\n",
    "\n",
    "    test_model = Model(train_iterator.get_next(), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value test/model/dense/kernel\n\t [[node test/model/dense/kernel/read (defined at <ipython-input-9-14069d675e7a>:69)  = Identity[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](test/model/dense/kernel)]]\n\nCaused by op 'test/model/dense/kernel/read', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1424, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 126, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 456, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 486, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 438, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2843, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2869, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3044, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3209, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3291, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-14-d93a16616732>\", line 7, in <module>\n    test_model = Model(train_iterator.get_next(), False)\n  File \"<ipython-input-10-6daf212d6ad1>\", line 9, in __init__\n    batch['morphs'], batch['out_lengths'], is_training)\n  File \"<ipython-input-9-14069d675e7a>\", line 69, in __init__\n    self.char_output = tf.layers.dense(output[:, :, :num_hidden], len(hangul))\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/core.py\", line 184, in dense\n    return layer.apply(inputs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 817, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py\", line 374, in __call__\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 746, in __call__\n    self.build(input_shapes)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py\", line 944, in build\n    trainable=True)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py\", line 288, in add_weight\n    getter=vs.get_variable)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 609, in add_weight\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/checkpointable/base.py\", line 639, in _add_variable_with_custom_getter\n    **kwargs_for_getter)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 1487, in get_variable\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 1237, in get_variable\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 540, in get_variable\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 492, in _true_getter\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 922, in _get_single_variable\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 183, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 146, in _variable_v1_call\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 125, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 2444, in default_variable_creator\n    expected_shape=expected_shape, import_scope=import_scope)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 187, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 1329, in __init__\n    constraint=constraint)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 1491, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_ops.py\", line 81, in identity\n    return gen_array_ops.identity(input, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 3454, in identity\n    \"Identity\", input=input, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value test/model/dense/kernel\n\t [[node test/model/dense/kernel/read (defined at <ipython-input-9-14069d675e7a>:69)  = Identity[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](test/model/dense/kernel)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value test/model/dense/kernel\n\t [[{{node test/model/dense/kernel/read}} = Identity[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](test/model/dense/kernel)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-a5e60b0cbff3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m input_string, lengths, embed_table, char_output, decoder_input = sess.run(\n\u001b[1;32m      8\u001b[0m     (test_model.encoder.inputs, test_model.decoder.out_lengths, char_embed_table, \n\u001b[0;32m----> 9\u001b[0;31m      test_model.decoder.char_output, test_model.decoder.decoder_inputs))\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value test/model/dense/kernel\n\t [[node test/model/dense/kernel/read (defined at <ipython-input-9-14069d675e7a>:69)  = Identity[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](test/model/dense/kernel)]]\n\nCaused by op 'test/model/dense/kernel/read', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1424, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 126, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 456, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 486, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 438, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2843, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2869, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3044, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3209, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3291, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-14-d93a16616732>\", line 7, in <module>\n    test_model = Model(train_iterator.get_next(), False)\n  File \"<ipython-input-10-6daf212d6ad1>\", line 9, in __init__\n    batch['morphs'], batch['out_lengths'], is_training)\n  File \"<ipython-input-9-14069d675e7a>\", line 69, in __init__\n    self.char_output = tf.layers.dense(output[:, :, :num_hidden], len(hangul))\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/core.py\", line 184, in dense\n    return layer.apply(inputs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 817, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py\", line 374, in __call__\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 746, in __call__\n    self.build(input_shapes)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py\", line 944, in build\n    trainable=True)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py\", line 288, in add_weight\n    getter=vs.get_variable)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 609, in add_weight\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/checkpointable/base.py\", line 639, in _add_variable_with_custom_getter\n    **kwargs_for_getter)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 1487, in get_variable\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 1237, in get_variable\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 540, in get_variable\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 492, in _true_getter\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 922, in _get_single_variable\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 183, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 146, in _variable_v1_call\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 125, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 2444, in default_variable_creator\n    expected_shape=expected_shape, import_scope=import_scope)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 187, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 1329, in __init__\n    constraint=constraint)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 1491, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_ops.py\", line 81, in identity\n    return gen_array_ops.identity(input, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 3454, in identity\n    \"Identity\", input=input, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value test/model/dense/kernel\n\t [[node test/model/dense/kernel/read (defined at <ipython-input-9-14069d675e7a>:69)  = Identity[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](test/model/dense/kernel)]]\n"
     ]
    }
   ],
   "source": [
    "# test some samples\n",
    "\n",
    "def cosine_distance_np(a, b):\n",
    "    normalize = np.linalg.norm(a, axis=1, keepdims=True) * np.linalg.norm(b, axis=0, keepdims=True)\n",
    "    return np.einsum('ki,ij->kj', a, b) / normalize\n",
    "\n",
    "input_string, lengths, embed_table, char_output, decoder_input = sess.run(\n",
    "    (test_model.encoder.inputs, test_model.decoder.out_lengths, char_embed_table, \n",
    "     test_model.decoder.char_output, test_model.decoder.decoder_inputs))\n",
    "\n",
    "for i in range(batch_size):\n",
    "    print(decode_string(input_string[i]))\n",
    "    print(decode_string(np.argmax(char_output[i, :lengths[i]], axis=1)))\n",
    "    print(decoder_input[i, :, 0])\n",
    "    #scores = cosine_distance_np(char_output[i][:lengths[i]], embed_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440: 0.059922635555267334\n",
      "Saved to models/charrnn-440\n",
      "450: -0.18869411945343018\n",
      "Saved to models/charrnn-450\n",
      "460: -0.10303229093551636\n",
      "Saved to models/charrnn-460\n",
      "470: -0.1552022099494934\n",
      "Saved to models/charrnn-470\n",
      "480: -0.10200667381286621\n",
      "Saved to models/charrnn-480\n",
      "490: -0.05547904968261719\n",
      "Saved to models/charrnn-490\n",
      "500: -0.14164602756500244\n",
      "Saved to models/charrnn-500\n",
      "510: -0.24593961238861084\n",
      "Saved to models/charrnn-510\n",
      "520: -0.1792566180229187\n",
      "Saved to models/charrnn-520\n",
      "530: -0.14285480976104736\n",
      "Saved to models/charrnn-530\n",
      "540: -0.09570342302322388\n",
      "Saved to models/charrnn-540\n",
      "550: -0.04417073726654053\n",
      "Saved to models/charrnn-550\n",
      "560: -0.2414391040802002\n",
      "Saved to models/charrnn-560\n",
      "570: -0.22570860385894775\n",
      "Saved to models/charrnn-570\n",
      "580: -0.2700360417366028\n",
      "Saved to models/charrnn-580\n",
      "590: -0.25528889894485474\n",
      "Saved to models/charrnn-590\n",
      "600: -0.2968563437461853\n",
      "Saved to models/charrnn-600\n",
      "610: -0.28264570236206055\n",
      "Saved to models/charrnn-610\n",
      "620: -0.19650888442993164\n",
      "Saved to models/charrnn-620\n",
      "630: -0.2434867024421692\n",
      "Saved to models/charrnn-630\n",
      "640: -0.2425856590270996\n",
      "Saved to models/charrnn-640\n",
      "650: -0.1453724503517151\n",
      "Saved to models/charrnn-650\n",
      "660: -0.33432674407958984\n",
      "Saved to models/charrnn-660\n",
      "670: -0.3146001100540161\n",
      "Saved to models/charrnn-670\n",
      "680: -0.24558240175247192\n",
      "Saved to models/charrnn-680\n",
      "690: -0.36693549156188965\n",
      "Saved to models/charrnn-690\n",
      "700: -0.2882198691368103\n",
      "Saved to models/charrnn-700\n",
      "710: -0.3910831809043884\n",
      "Saved to models/charrnn-710\n",
      "720: -0.3201332092285156\n",
      "Saved to models/charrnn-720\n",
      "730: -0.3170439600944519\n",
      "Saved to models/charrnn-730\n",
      "740: -0.3067587614059448\n",
      "Saved to models/charrnn-740\n",
      "750: -0.34696269035339355\n",
      "Saved to models/charrnn-750\n",
      "760: -0.39304667711257935\n",
      "Saved to models/charrnn-760\n",
      "770: -0.33757495880126953\n",
      "Saved to models/charrnn-770\n",
      "780: -0.32385510206222534\n",
      "Saved to models/charrnn-780\n",
      "790: -0.382740318775177\n",
      "Saved to models/charrnn-790\n",
      "800: -0.31920701265335083\n",
      "Saved to models/charrnn-800\n",
      "810: -0.25140005350112915\n",
      "Saved to models/charrnn-810\n",
      "820: -0.22863948345184326\n",
      "Saved to models/charrnn-820\n",
      "830: -0.13495808839797974\n",
      "Saved to models/charrnn-830\n",
      "840: -0.3428409695625305\n",
      "Saved to models/charrnn-840\n",
      "850: -0.3799542784690857\n",
      "Saved to models/charrnn-850\n",
      "860: -0.43535172939300537\n",
      "Saved to models/charrnn-860\n",
      "870: -0.36293715238571167\n",
      "Saved to models/charrnn-870\n",
      "880: -0.34986740350723267\n",
      "Saved to models/charrnn-880\n",
      "890: -0.36094069480895996\n",
      "Saved to models/charrnn-890\n",
      "900: -0.32736724615097046\n",
      "Saved to models/charrnn-900\n",
      "910: -0.3674655556678772\n",
      "Saved to models/charrnn-910\n",
      "920: -0.44464290142059326\n",
      "Saved to models/charrnn-920\n",
      "930: -0.392400860786438\n",
      "Saved to models/charrnn-930\n",
      "940: -0.36903518438339233\n",
      "Saved to models/charrnn-940\n",
      "950: -0.40990471839904785\n",
      "Saved to models/charrnn-950\n",
      "960: -0.3913837671279907\n",
      "Saved to models/charrnn-960\n",
      "970: -0.338497519493103\n",
      "Saved to models/charrnn-970\n",
      "980: -0.2806192636489868\n",
      "Saved to models/charrnn-980\n",
      "990: -0.4596136212348938\n",
      "Saved to models/charrnn-990\n",
      "1000: -0.3723640441894531\n",
      "Saved to models/charrnn-1000\n",
      "1010: -0.4161113500595093\n",
      "Saved to models/charrnn-1010\n",
      "1020: -0.31259626150131226\n",
      "Saved to models/charrnn-1020\n",
      "1030: -0.385178804397583\n",
      "Saved to models/charrnn-1030\n",
      "1040: -0.39286231994628906\n",
      "Saved to models/charrnn-1040\n",
      "1050: -0.4372745752334595\n",
      "Saved to models/charrnn-1050\n",
      "1060: -0.3322451710700989\n",
      "Saved to models/charrnn-1060\n",
      "1070: -0.4191129803657532\n",
      "Saved to models/charrnn-1070\n",
      "1080: -0.3852907419204712\n",
      "Saved to models/charrnn-1080\n",
      "1090: -0.4357796311378479\n",
      "Saved to models/charrnn-1090\n",
      "1100: -0.44501662254333496\n",
      "Saved to models/charrnn-1100\n",
      "1110: -0.41592973470687866\n",
      "Saved to models/charrnn-1110\n",
      "1120: -0.4268985986709595\n",
      "Saved to models/charrnn-1120\n",
      "1130: -0.42922741174697876\n",
      "Saved to models/charrnn-1130\n",
      "1140: -0.45036107301712036\n",
      "Saved to models/charrnn-1140\n",
      "1150: -0.40756428241729736\n",
      "Saved to models/charrnn-1150\n",
      "1160: -0.43314146995544434\n",
      "Saved to models/charrnn-1160\n",
      "1170: -0.46882355213165283\n",
      "Saved to models/charrnn-1170\n",
      "1180: -0.4448249936103821\n",
      "Saved to models/charrnn-1180\n",
      "1190: -0.4657289981842041\n",
      "Saved to models/charrnn-1190\n",
      "1200: -0.4657020568847656\n",
      "Saved to models/charrnn-1200\n",
      "1210: -0.4561379551887512\n",
      "Saved to models/charrnn-1210\n",
      "1220: -0.4941015839576721\n",
      "Saved to models/charrnn-1220\n",
      "1230: -0.45722997188568115\n",
      "Saved to models/charrnn-1230\n",
      "1240: -0.4717289209365845\n",
      "Saved to models/charrnn-1240\n",
      "1250: -0.4897528886795044\n",
      "Saved to models/charrnn-1250\n",
      "1260: -0.46468663215637207\n",
      "Saved to models/charrnn-1260\n",
      "1270: -0.43110227584838867\n",
      "Saved to models/charrnn-1270\n",
      "1280: -0.3876357078552246\n",
      "Saved to models/charrnn-1280\n",
      "1290: -0.4724709987640381\n",
      "Saved to models/charrnn-1290\n",
      "1300: -0.3964395523071289\n",
      "Saved to models/charrnn-1300\n",
      "1310: -0.46178138256073\n",
      "Saved to models/charrnn-1310\n",
      "1320: -0.4092899560928345\n",
      "Saved to models/charrnn-1320\n",
      "1330: -0.44011974334716797\n",
      "Saved to models/charrnn-1330\n",
      "1340: -0.46803218126296997\n",
      "Saved to models/charrnn-1340\n",
      "1350: -0.4414331912994385\n",
      "Saved to models/charrnn-1350\n",
      "1360: -0.4635552763938904\n",
      "Saved to models/charrnn-1360\n",
      "1370: -0.30053359270095825\n",
      "Saved to models/charrnn-1370\n",
      "1380: -0.46493780612945557\n",
      "Saved to models/charrnn-1380\n",
      "1390: -0.46192634105682373\n",
      "Saved to models/charrnn-1390\n",
      "1400: -0.47997087240219116\n",
      "Saved to models/charrnn-1400\n",
      "1410: -0.4823834300041199\n",
      "Saved to models/charrnn-1410\n",
      "1420: -0.49810588359832764\n",
      "Saved to models/charrnn-1420\n",
      "1430: -0.471252977848053\n",
      "Saved to models/charrnn-1430\n",
      "1440: -0.46491098403930664\n",
      "Saved to models/charrnn-1440\n",
      "1450: -0.3745465874671936\n",
      "Saved to models/charrnn-1450\n",
      "1460: -0.49595850706100464\n",
      "Saved to models/charrnn-1460\n",
      "1470: -0.4539281129837036\n",
      "Saved to models/charrnn-1470\n",
      "1480: -0.46427518129348755\n",
      "Saved to models/charrnn-1480\n",
      "1490: -0.48274731636047363\n",
      "Saved to models/charrnn-1490\n",
      "1500: -0.3897254467010498\n",
      "Saved to models/charrnn-1500\n",
      "1510: -0.46355026960372925\n",
      "Saved to models/charrnn-1510\n",
      "1520: -0.45518958568573\n",
      "Saved to models/charrnn-1520\n",
      "1530: -0.4198768138885498\n",
      "Saved to models/charrnn-1530\n",
      "1540: -0.4852150082588196\n",
      "Saved to models/charrnn-1540\n",
      "1550: -0.469307541847229\n",
      "Saved to models/charrnn-1550\n",
      "1560: -0.46414273977279663\n",
      "Saved to models/charrnn-1560\n",
      "1570: -0.47733640670776367\n",
      "Saved to models/charrnn-1570\n",
      "1580: -0.4970707297325134\n",
      "Saved to models/charrnn-1580\n",
      "1590: -0.4417051672935486\n",
      "Saved to models/charrnn-1590\n",
      "1600: -0.47311145067214966\n",
      "Saved to models/charrnn-1600\n",
      "1610: -0.4586135745048523\n",
      "Saved to models/charrnn-1610\n",
      "1620: -0.4673916697502136\n",
      "Saved to models/charrnn-1620\n",
      "1630: -0.489301860332489\n",
      "Saved to models/charrnn-1630\n",
      "1640: -0.44583743810653687\n",
      "Saved to models/charrnn-1640\n",
      "1650: -0.47011107206344604\n",
      "Saved to models/charrnn-1650\n",
      "1660: -0.4771515130996704\n",
      "Saved to models/charrnn-1660\n",
      "1670: -0.5044726729393005\n",
      "Saved to models/charrnn-1670\n",
      "1680: -0.39927107095718384\n",
      "Saved to models/charrnn-1680\n",
      "1690: -0.47056978940963745\n",
      "Saved to models/charrnn-1690\n",
      "1700: -0.3813878893852234\n",
      "Saved to models/charrnn-1700\n",
      "1710: -0.48521721363067627\n",
      "Saved to models/charrnn-1710\n",
      "1720: -0.4739910960197449\n",
      "Saved to models/charrnn-1720\n",
      "1730: -0.5010361671447754\n",
      "Saved to models/charrnn-1730\n",
      "1740: -0.46840953826904297\n",
      "Saved to models/charrnn-1740\n",
      "1750: -0.47419077157974243\n",
      "Saved to models/charrnn-1750\n",
      "1760: -0.4896698594093323\n",
      "Saved to models/charrnn-1760\n",
      "1770: -0.5309417843818665\n",
      "Saved to models/charrnn-1770\n",
      "1780: -0.48174601793289185\n",
      "Saved to models/charrnn-1780\n",
      "1790: -0.4759271740913391\n",
      "Saved to models/charrnn-1790\n",
      "1800: -0.4844009280204773\n",
      "Saved to models/charrnn-1800\n",
      "1810: -0.48910999298095703\n",
      "Saved to models/charrnn-1810\n",
      "1820: -0.4759339690208435\n",
      "Saved to models/charrnn-1820\n",
      "1830: -0.48969894647598267\n",
      "Saved to models/charrnn-1830\n",
      "1840: -0.5364112854003906\n",
      "Saved to models/charrnn-1840\n",
      "1850: -0.48455578088760376\n",
      "Saved to models/charrnn-1850\n",
      "1860: -0.4819580316543579\n",
      "Saved to models/charrnn-1860\n",
      "1870: -0.49458616971969604\n",
      "Saved to models/charrnn-1870\n",
      "1880: -0.4706777334213257\n",
      "Saved to models/charrnn-1880\n",
      "1890: -0.4853252172470093\n",
      "Saved to models/charrnn-1890\n",
      "1900: -0.4811597466468811\n",
      "Saved to models/charrnn-1900\n",
      "1910: -0.49496936798095703\n",
      "Saved to models/charrnn-1910\n",
      "1920: -0.4706574082374573\n",
      "Saved to models/charrnn-1920\n",
      "1930: -0.4815780520439148\n",
      "Saved to models/charrnn-1930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1940: -0.4804348945617676\n",
      "Saved to models/charrnn-1940\n",
      "1950: -0.4864816665649414\n",
      "Saved to models/charrnn-1950\n",
      "1960: -0.49740123748779297\n",
      "Saved to models/charrnn-1960\n",
      "1970: -0.4485020637512207\n",
      "Saved to models/charrnn-1970\n",
      "1980: -0.49094080924987793\n",
      "Saved to models/charrnn-1980\n",
      "1990: -0.5039564371109009\n",
      "Saved to models/charrnn-1990\n",
      "2000: -0.5033395290374756\n",
      "Saved to models/charrnn-2000\n",
      "2010: -0.5135948061943054\n",
      "Saved to models/charrnn-2010\n",
      "2020: -0.39885735511779785\n",
      "Saved to models/charrnn-2020\n",
      "2030: -0.4721015691757202\n",
      "Saved to models/charrnn-2030\n",
      "2040: -0.5031055212020874\n",
      "Saved to models/charrnn-2040\n",
      "2050: -0.5098269581794739\n",
      "Saved to models/charrnn-2050\n",
      "2060: -0.4815976619720459\n",
      "Saved to models/charrnn-2060\n",
      "2070: -0.48835116624832153\n",
      "Saved to models/charrnn-2070\n",
      "2080: -0.4704509973526001\n",
      "Saved to models/charrnn-2080\n",
      "2090: -0.5286684036254883\n",
      "Saved to models/charrnn-2090\n",
      "2100: -0.44491422176361084\n",
      "Saved to models/charrnn-2100\n",
      "2110: -0.48395872116088867\n",
      "Saved to models/charrnn-2110\n",
      "2120: -0.46608424186706543\n",
      "Saved to models/charrnn-2120\n",
      "2130: -0.4960539937019348\n",
      "Saved to models/charrnn-2130\n",
      "2140: -0.5084341764450073\n",
      "Saved to models/charrnn-2140\n",
      "2150: -0.5015984773635864\n",
      "Saved to models/charrnn-2150\n",
      "2160: -0.5169476866722107\n",
      "Saved to models/charrnn-2160\n",
      "2170: -0.5152862668037415\n",
      "Saved to models/charrnn-2170\n",
      "2180: -0.5205074548721313\n",
      "Saved to models/charrnn-2180\n",
      "2190: -0.4989774227142334\n",
      "Saved to models/charrnn-2190\n",
      "2200: -0.5105617046356201\n",
      "Saved to models/charrnn-2200\n",
      "2210: -0.4741186499595642\n",
      "Saved to models/charrnn-2210\n",
      "2220: -0.4949818253517151\n",
      "Saved to models/charrnn-2220\n",
      "2230: -0.4953002333641052\n",
      "Saved to models/charrnn-2230\n",
      "2240: -0.5008945465087891\n",
      "Saved to models/charrnn-2240\n",
      "2250: -0.510429859161377\n",
      "Saved to models/charrnn-2250\n",
      "2260: -0.49912166595458984\n",
      "Saved to models/charrnn-2260\n",
      "2270: -0.48859119415283203\n",
      "Saved to models/charrnn-2270\n",
      "2280: -0.49595320224761963\n",
      "Saved to models/charrnn-2280\n",
      "2290: -0.503305196762085\n",
      "Saved to models/charrnn-2290\n",
      "2300: -0.5146194696426392\n",
      "Saved to models/charrnn-2300\n",
      "2310: -0.5356068015098572\n",
      "Saved to models/charrnn-2310\n",
      "2320: -0.5024372935295105\n",
      "Saved to models/charrnn-2320\n",
      "2330: -0.5002716779708862\n",
      "Saved to models/charrnn-2330\n",
      "2340: -0.5085781812667847\n",
      "Saved to models/charrnn-2340\n",
      "2350: -0.4957195520401001\n",
      "Saved to models/charrnn-2350\n",
      "2360: -0.48156410455703735\n",
      "Saved to models/charrnn-2360\n",
      "2370: -0.5340315103530884\n",
      "Saved to models/charrnn-2370\n",
      "2380: -0.5003992319107056\n",
      "Saved to models/charrnn-2380\n",
      "2390: -0.4688112139701843\n",
      "Saved to models/charrnn-2390\n",
      "2400: -0.5177180171012878\n",
      "Saved to models/charrnn-2400\n",
      "2410: -0.5052591562271118\n",
      "Saved to models/charrnn-2410\n",
      "2420: -0.5113157629966736\n",
      "Saved to models/charrnn-2420\n",
      "2430: -0.47979313135147095\n",
      "Saved to models/charrnn-2430\n",
      "2440: -0.5016972422599792\n",
      "Saved to models/charrnn-2440\n",
      "2450: -0.5175098180770874\n",
      "Saved to models/charrnn-2450\n",
      "2460: -0.47600775957107544\n",
      "Saved to models/charrnn-2460\n",
      "2470: -0.503513514995575\n",
      "Saved to models/charrnn-2470\n",
      "2480: -0.5060780644416809\n",
      "Saved to models/charrnn-2480\n",
      "2490: -0.5080738067626953\n",
      "Saved to models/charrnn-2490\n",
      "2500: -0.5167624354362488\n",
      "Saved to models/charrnn-2500\n",
      "2510: -0.5202091932296753\n",
      "Saved to models/charrnn-2510\n",
      "2520: -0.5005869269371033\n",
      "Saved to models/charrnn-2520\n",
      "2530: -0.48949575424194336\n",
      "Saved to models/charrnn-2530\n",
      "2540: -0.4821808338165283\n",
      "Saved to models/charrnn-2540\n",
      "2550: -0.4572399854660034\n",
      "Saved to models/charrnn-2550\n",
      "2560: -0.5101192593574524\n",
      "Saved to models/charrnn-2560\n",
      "2570: -0.5366174578666687\n",
      "Saved to models/charrnn-2570\n",
      "2580: -0.5054775476455688\n",
      "Saved to models/charrnn-2580\n",
      "2590: -0.5132560729980469\n",
      "Saved to models/charrnn-2590\n",
      "2600: -0.5244855880737305\n",
      "Saved to models/charrnn-2600\n",
      "2610: -0.4977934956550598\n",
      "Saved to models/charrnn-2610\n",
      "2620: -0.4954001307487488\n",
      "Saved to models/charrnn-2620\n",
      "2630: -0.503332257270813\n",
      "Saved to models/charrnn-2630\n",
      "2640: -0.5227345824241638\n",
      "Saved to models/charrnn-2640\n",
      "2650: -0.5148319602012634\n",
      "Saved to models/charrnn-2650\n",
      "2660: -0.5322662591934204\n",
      "Saved to models/charrnn-2660\n",
      "2670: -0.48434436321258545\n",
      "Saved to models/charrnn-2670\n",
      "2680: -0.5228531360626221\n",
      "Saved to models/charrnn-2680\n",
      "2690: -0.4694775342941284\n",
      "Saved to models/charrnn-2690\n",
      "2700: -0.503805935382843\n",
      "Saved to models/charrnn-2700\n",
      "2710: -0.4011053442955017\n",
      "Saved to models/charrnn-2710\n",
      "2720: -0.539884090423584\n",
      "Saved to models/charrnn-2720\n",
      "2730: -0.4903377890586853\n",
      "Saved to models/charrnn-2730\n",
      "2740: -0.49544668197631836\n",
      "Saved to models/charrnn-2740\n",
      "2750: -0.4994592070579529\n",
      "Saved to models/charrnn-2750\n",
      "2760: -0.5151784420013428\n",
      "Saved to models/charrnn-2760\n",
      "2770: -0.5176959037780762\n",
      "Saved to models/charrnn-2770\n",
      "2780: -0.4975578784942627\n",
      "Saved to models/charrnn-2780\n",
      "2790: -0.5018386840820312\n",
      "Saved to models/charrnn-2790\n",
      "2800: -0.5126826763153076\n",
      "Saved to models/charrnn-2800\n",
      "2810: -0.518777072429657\n",
      "Saved to models/charrnn-2810\n",
      "2820: -0.5195298194885254\n",
      "Saved to models/charrnn-2820\n",
      "2830: -0.5245048999786377\n",
      "Saved to models/charrnn-2830\n",
      "2840: -0.543075442314148\n",
      "Saved to models/charrnn-2840\n",
      "2850: -0.46597498655319214\n",
      "Saved to models/charrnn-2850\n",
      "2860: -0.519334077835083\n",
      "Saved to models/charrnn-2860\n",
      "2870: -0.5321291089057922\n",
      "Saved to models/charrnn-2870\n",
      "2880: -0.5106576681137085\n",
      "Saved to models/charrnn-2880\n",
      "2890: -0.5077800750732422\n",
      "Saved to models/charrnn-2890\n",
      "2900: -0.49678516387939453\n",
      "Saved to models/charrnn-2900\n",
      "2910: -0.5568311214447021\n",
      "Saved to models/charrnn-2910\n",
      "2920: -0.5160696506500244\n",
      "Saved to models/charrnn-2920\n",
      "2930: -0.5450167655944824\n",
      "Saved to models/charrnn-2930\n",
      "2940: -0.5276716947555542\n",
      "Saved to models/charrnn-2940\n",
      "2950: -0.5110675692558289\n",
      "Saved to models/charrnn-2950\n",
      "2960: -0.49976450204849243\n",
      "Saved to models/charrnn-2960\n",
      "2970: -0.49399805068969727\n",
      "Saved to models/charrnn-2970\n",
      "2980: -0.503027081489563\n",
      "Saved to models/charrnn-2980\n",
      "2990: -0.5298712253570557\n",
      "Saved to models/charrnn-2990\n",
      "3000: -0.4769037365913391\n",
      "Saved to models/charrnn-3000\n",
      "3010: -0.5355148315429688\n",
      "Saved to models/charrnn-3010\n",
      "3020: -0.50628662109375\n",
      "Saved to models/charrnn-3020\n",
      "3030: -0.5145536661148071\n",
      "Saved to models/charrnn-3030\n",
      "3040: -0.5067455172538757\n",
      "Saved to models/charrnn-3040\n",
      "3050: -0.5230558514595032\n",
      "Saved to models/charrnn-3050\n",
      "3060: -0.5185410976409912\n",
      "Saved to models/charrnn-3060\n",
      "3070: -0.48210012912750244\n",
      "Saved to models/charrnn-3070\n",
      "3080: -0.4887532591819763\n",
      "Saved to models/charrnn-3080\n",
      "3090: -0.5417764186859131\n",
      "Saved to models/charrnn-3090\n",
      "3100: -0.5007492303848267\n",
      "Saved to models/charrnn-3100\n",
      "3110: -0.5245324373245239\n",
      "Saved to models/charrnn-3110\n",
      "3120: -0.5275254249572754\n",
      "Saved to models/charrnn-3120\n",
      "3130: -0.5112613439559937\n",
      "Saved to models/charrnn-3130\n",
      "3140: -0.49731016159057617\n",
      "Saved to models/charrnn-3140\n",
      "3150: -0.47059929370880127\n",
      "Saved to models/charrnn-3150\n",
      "3160: -0.46706968545913696\n",
      "Saved to models/charrnn-3160\n",
      "3170: -0.5341005325317383\n",
      "Saved to models/charrnn-3170\n",
      "3180: -0.549219012260437\n",
      "Saved to models/charrnn-3180\n",
      "3190: -0.5132932662963867\n",
      "Saved to models/charrnn-3190\n",
      "3200: -0.5267722606658936\n",
      "Saved to models/charrnn-3200\n",
      "3210: -0.520155668258667\n",
      "Saved to models/charrnn-3210\n",
      "3220: -0.4544706344604492\n",
      "Saved to models/charrnn-3220\n",
      "3230: -0.5297993421554565\n",
      "Saved to models/charrnn-3230\n",
      "3240: -0.5012285709381104\n",
      "Saved to models/charrnn-3240\n",
      "3250: -0.514274537563324\n",
      "Saved to models/charrnn-3250\n",
      "3260: -0.5078363418579102\n",
      "Saved to models/charrnn-3260\n",
      "3270: -0.49000948667526245\n",
      "Saved to models/charrnn-3270\n",
      "3280: -0.5378826856613159\n",
      "Saved to models/charrnn-3280\n",
      "3290: -0.5292783975601196\n",
      "Saved to models/charrnn-3290\n",
      "3300: -0.5402213335037231\n",
      "Saved to models/charrnn-3300\n",
      "3310: -0.5421187281608582\n",
      "Saved to models/charrnn-3310\n",
      "3320: -0.4918172359466553\n",
      "Saved to models/charrnn-3320\n",
      "3330: -0.525097131729126\n",
      "Saved to models/charrnn-3330\n",
      "3340: -0.5331968069076538\n",
      "Saved to models/charrnn-3340\n",
      "3350: -0.5077205896377563\n",
      "Saved to models/charrnn-3350\n",
      "3360: -0.5309738516807556\n",
      "Saved to models/charrnn-3360\n",
      "3370: -0.5641988515853882\n",
      "Saved to models/charrnn-3370\n",
      "3380: -0.5261980295181274\n",
      "Saved to models/charrnn-3380\n",
      "3390: -0.5002861022949219\n",
      "Saved to models/charrnn-3390\n",
      "3400: -0.529823899269104\n",
      "Saved to models/charrnn-3400\n",
      "3410: -0.49367284774780273\n",
      "Saved to models/charrnn-3410\n",
      "3420: -0.5049501061439514\n",
      "Saved to models/charrnn-3420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3430: -0.4880707859992981\n",
      "Saved to models/charrnn-3430\n",
      "3440: -0.5509637594223022\n",
      "Saved to models/charrnn-3440\n",
      "3450: -0.5092551708221436\n",
      "Saved to models/charrnn-3450\n",
      "3460: -0.5341881513595581\n",
      "Saved to models/charrnn-3460\n",
      "3470: -0.525292158126831\n",
      "Saved to models/charrnn-3470\n",
      "3480: -0.5004032254219055\n",
      "Saved to models/charrnn-3480\n",
      "3490: -0.48614048957824707\n",
      "Saved to models/charrnn-3490\n",
      "3500: -0.5389701128005981\n",
      "Saved to models/charrnn-3500\n",
      "3510: -0.5100560188293457\n",
      "Saved to models/charrnn-3510\n",
      "3520: -0.4937590956687927\n",
      "Saved to models/charrnn-3520\n",
      "3530: -0.5226720571517944\n",
      "Saved to models/charrnn-3530\n",
      "3540: -0.5455232858657837\n",
      "Saved to models/charrnn-3540\n",
      "3550: -0.5306717157363892\n",
      "Saved to models/charrnn-3550\n",
      "3560: -0.5230414867401123\n",
      "Saved to models/charrnn-3560\n",
      "3570: -0.5041854381561279\n",
      "Saved to models/charrnn-3570\n",
      "3580: -0.5299737453460693\n",
      "Saved to models/charrnn-3580\n",
      "3590: -0.5173258781433105\n",
      "Saved to models/charrnn-3590\n",
      "3600: -0.5077744126319885\n",
      "Saved to models/charrnn-3600\n",
      "3610: -0.5010141134262085\n",
      "Saved to models/charrnn-3610\n",
      "3620: -0.509716808795929\n",
      "Saved to models/charrnn-3620\n",
      "3630: -0.5053452253341675\n",
      "Saved to models/charrnn-3630\n",
      "3640: -0.5404319167137146\n",
      "Saved to models/charrnn-3640\n",
      "3650: -0.5053998231887817\n",
      "Saved to models/charrnn-3650\n",
      "3660: -0.4569183588027954\n",
      "Saved to models/charrnn-3660\n",
      "3670: -0.5020896196365356\n",
      "Saved to models/charrnn-3670\n",
      "3680: -0.5001968145370483\n",
      "Saved to models/charrnn-3680\n",
      "3690: -0.5135907530784607\n",
      "Saved to models/charrnn-3690\n",
      "3700: -0.5397009253501892\n",
      "Saved to models/charrnn-3700\n",
      "3710: -0.5318673849105835\n",
      "Saved to models/charrnn-3710\n",
      "3720: -0.5512874722480774\n",
      "Saved to models/charrnn-3720\n",
      "3730: -0.5454521179199219\n",
      "Saved to models/charrnn-3730\n",
      "3740: -0.4940319061279297\n",
      "Saved to models/charrnn-3740\n",
      "3750: -0.5306669473648071\n",
      "Saved to models/charrnn-3750\n",
      "3760: -0.5194134712219238\n",
      "Saved to models/charrnn-3760\n",
      "3770: -0.5333704352378845\n",
      "Saved to models/charrnn-3770\n",
      "3780: -0.5699301958084106\n",
      "Saved to models/charrnn-3780\n",
      "3790: -0.46893978118896484\n",
      "Saved to models/charrnn-3790\n",
      "3800: -0.40635234117507935\n",
      "Saved to models/charrnn-3800\n",
      "3810: -0.5357565879821777\n",
      "Saved to models/charrnn-3810\n",
      "3820: -0.5452535152435303\n",
      "Saved to models/charrnn-3820\n",
      "3830: -0.5243058204650879\n",
      "Saved to models/charrnn-3830\n",
      "3840: -0.5409078598022461\n",
      "Saved to models/charrnn-3840\n",
      "3850: -0.5007033348083496\n",
      "Saved to models/charrnn-3850\n",
      "3860: -0.4749721884727478\n",
      "Saved to models/charrnn-3860\n",
      "3870: -0.5247498750686646\n",
      "Saved to models/charrnn-3870\n",
      "3880: -0.5248054265975952\n",
      "Saved to models/charrnn-3880\n",
      "3890: -0.5562335252761841\n",
      "Saved to models/charrnn-3890\n",
      "3900: -0.5593281984329224\n",
      "Saved to models/charrnn-3900\n",
      "3910: -0.5231766700744629\n",
      "Saved to models/charrnn-3910\n",
      "3920: -0.5600361824035645\n",
      "Saved to models/charrnn-3920\n",
      "3930: -0.5327089428901672\n",
      "Saved to models/charrnn-3930\n",
      "3940: -0.5371463298797607\n",
      "Saved to models/charrnn-3940\n",
      "3950: -0.5352010130882263\n",
      "Saved to models/charrnn-3950\n",
      "3960: -0.5527747869491577\n",
      "Saved to models/charrnn-3960\n",
      "3970: -0.5252969861030579\n",
      "Saved to models/charrnn-3970\n",
      "3980: -0.5318311452865601\n",
      "Saved to models/charrnn-3980\n",
      "3990: -0.5200804471969604\n",
      "Saved to models/charrnn-3990\n",
      "4000: -0.502571702003479\n",
      "Saved to models/charrnn-4000\n",
      "4010: -0.4710766077041626\n",
      "Saved to models/charrnn-4010\n",
      "4020: -0.5368883609771729\n",
      "Saved to models/charrnn-4020\n",
      "4030: -0.48961710929870605\n",
      "Saved to models/charrnn-4030\n",
      "4040: -0.4738379716873169\n",
      "Saved to models/charrnn-4040\n",
      "4050: -0.49143606424331665\n",
      "Saved to models/charrnn-4050\n",
      "4060: -0.5313678979873657\n",
      "Saved to models/charrnn-4060\n",
      "4070: -0.5233827829360962\n",
      "Saved to models/charrnn-4070\n",
      "4080: -0.47244375944137573\n",
      "Saved to models/charrnn-4080\n",
      "4090: -0.5172065496444702\n",
      "Saved to models/charrnn-4090\n",
      "4100: -0.5213994383811951\n",
      "Saved to models/charrnn-4100\n",
      "4110: -0.539786159992218\n",
      "Saved to models/charrnn-4110\n",
      "4120: -0.5247434973716736\n",
      "Saved to models/charrnn-4120\n",
      "4130: -0.5233787298202515\n",
      "Saved to models/charrnn-4130\n",
      "4140: -0.5127097964286804\n",
      "Saved to models/charrnn-4140\n",
      "4150: -0.533741295337677\n",
      "Saved to models/charrnn-4150\n",
      "4160: -0.532446563243866\n",
      "Saved to models/charrnn-4160\n",
      "4170: -0.5289415121078491\n",
      "Saved to models/charrnn-4170\n",
      "4180: -0.5391340255737305\n",
      "Saved to models/charrnn-4180\n",
      "4190: -0.49926239252090454\n",
      "Saved to models/charrnn-4190\n",
      "4200: -0.5356367826461792\n",
      "Saved to models/charrnn-4200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-3fb3166e3ebe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_summary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrain_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# run\n",
    "while True:\n",
    "    _, loss, step, log = sess.run((model.optimize, model.total_loss, model.global_step, model.training_summary))\n",
    "    \n",
    "    train_writer.add_summary(log, step)\n",
    "    \n",
    "    if step % 10 == 0:\n",
    "        print(\"{}: {}\".format(step, loss))\n",
    "        \n",
    "        save_path = saver.save(sess, \"models/charrnn\", step)\n",
    "        print('Saved to', save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
